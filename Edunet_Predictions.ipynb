{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Vf_Z8oLw-XgHsN2bLhKQrhcSZydgL49C",
      "authorship_tag": "ABX9TyOPsWDH58UQZ38HFrYHTyXo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AasthathecoderX/Edunet_Energy/blob/main/Edunet_Predictions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8fc8f87"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Replace '/path/to/your/dataset.csv' with the actual path to your file in Google Drive\n",
        "# Example: '/content/drive/MyDrive/data/my_dataset.csv'\n",
        "try:\n",
        "    df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Datasets/Solar power plant dataset/2022 All zones/Final Dataset.xlsx - Sheet1.csv')\n",
        "    print(\"Dataset loaded successfully!\")\n",
        "    display(df.head())\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: Make sure the file path is correct and the file exists in your Google Drive.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16e7d8af"
      },
      "source": [
        "display(df.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check all columns in the dataset\n",
        "print(\"All columns in the dataset:\")\n",
        "print(df.columns.tolist())\n",
        "print(\"\\nDataset shape:\", df.shape)\n",
        "print(\"\\nFirst few rows:\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "616uNEHOiYyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f559033c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Select only numerical columns for outlier detection\n",
        "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "# Create box plots for each numerical column\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, col in enumerate(numerical_cols):\n",
        "    plt.subplot(3, 3, i + 1)\n",
        "    sns.boxplot(y=df[col])\n",
        "    plt.title(col)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d62abc0"
      },
      "source": [
        "# 1. Identify and handle the categorical column 'Unnamed: 0'.\n",
        "\n",
        "df['Unnamed: 0'] = df['Unnamed: 0'].fillna(method='ffill')\n",
        "\n",
        "\n",
        "df['Unnamed: 0'] = df['Unnamed: 0'].fillna('UNKNOWN')\n",
        "\n",
        "\n",
        "# Convert the categorical column to numerical using one-hot encoding\n",
        "df = pd.get_dummies(df, columns=['Unnamed: 0'], prefix='Zone')\n",
        "\n",
        "\n",
        "# 2. Examine the column names to identify the target variable related to solar generation.\n",
        "\n",
        "target_variable = '1)All Sky Surface Shortwave Downward Irradiance'\n",
        "\n",
        "# 3. Separate the target variable from the features.\n",
        "X = df.drop(columns=[target_variable])\n",
        "y = df[target_variable]\n",
        "\n",
        "# 4. Select the numerical features for scaling.\n",
        "\n",
        "numerical_cols_for_scaling = X.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "# 5. Apply a scaling technique (e.g., StandardScaler) to the numerical features.\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X[numerical_cols_for_scaling] = scaler.fit_transform(X[numerical_cols_for_scaling])\n",
        "\n",
        "display(X.head())\n",
        "display(y.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4822e4a5"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "print(\"Shape of y_test:\", y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82e947d2"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "# Instantiate the GradientBoostingRegressor with default parameters\n",
        "gbr = GradientBoostingRegressor()\n",
        "\n",
        "# Train the model using the X_train and y_train dataframes\n",
        "gbr.fit(X_train, y_train)\n",
        "\n",
        "print(\"Model training complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d585095c"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = gbr.predict(X_test)\n",
        "\n",
        "# Calculate the metrics\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Print the metrics\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
        "print(f\"R-squared (R2): {r2:.4f}\")\n",
        "print(f\"Accuracy (R2): {r2*100:.2f}%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4161a65"
      },
      "source": [
        "# After fitting your scaler and doing get_dummies:\n",
        "import joblib\n",
        "\n",
        "# Save the columns of X after encoding (important!)\n",
        "joblib.dump(X.columns.tolist(), \"solar_feature_columns.joblib\")\n",
        "joblib.dump(scaler, \"solar_scaler.joblib\")\n",
        "joblib.dump(gbr, \"solar_prediction_model.joblib\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# NEW SECTION: Train 5-Feature Models for Frontend\n",
        "# ============================================\n",
        "# This section creates models that match the frontend inputs:\n",
        "# latitude, longitude, roof_area, orientation_code, slope\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import joblib\n",
        "\n",
        "print(\"Creating synthetic dataset with 5 features matching frontend...\")\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "n_samples = 1000\n",
        "\n",
        "# Feature 1: Latitude (India range: 8 to 35)\n",
        "latitudes = np.random.uniform(8, 35, n_samples)\n",
        "\n",
        "# Feature 2: Longitude (India range: 68 to 97)\n",
        "longitudes = np.random.uniform(68, 97, n_samples)\n",
        "\n",
        "# Feature 3: Roof Area (sq meters: 50 to 500)\n",
        "roof_areas = np.random.uniform(50, 500, n_samples)\n",
        "\n",
        "# Feature 4: Orientation (0=North, 1=East, 2=South, 3=West)\n",
        "orientations = np.random.randint(0, 4, n_samples)\n",
        "\n",
        "# Feature 5: Slope (degrees: 0 to 45)\n",
        "slopes = np.random.uniform(0, 45, n_samples)\n",
        "\n",
        "# Create DataFrame\n",
        "data_5features = pd.DataFrame({\n",
        "    'latitude': latitudes,\n",
        "    'longitude': longitudes,\n",
        "    'roof_area': roof_areas,\n",
        "    'orientation_code': orientations,\n",
        "    'slope': slopes\n",
        "})\n",
        "\n",
        "print(f\"Generated {n_samples} samples with 5 features\")\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(data_5features.head())"
      ],
      "metadata": {
        "id": "QvdzmVe0i2sy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate realistic target variables based on the features\n",
        "print(\"\\nGenerating target variables...\")\n",
        "\n",
        "\n",
        "# Formula considers: roof area, latitude (solar irradiance), orientation, slope\n",
        "# South-facing panels with optimal slope produce more energy\n",
        "\n",
        "\n",
        "solar_irradiance_factor = 1.5 - (np.abs(latitudes - 15) / 50)\n",
        "\n",
        "# Orientation factor (South=best in Northern hemisphere)\n",
        "orientation_factors = {\n",
        "    0: 0.7,  # North\n",
        "    1: 0.85, # East\n",
        "    2: 1.0,  # South (best)\n",
        "    3: 0.85  # West\n",
        "}\n",
        "orientation_multiplier = np.array([orientation_factors[o] for o in orientations])\n",
        "\n",
        "# Slope factor (optimal around 20-30 degrees)\n",
        "slope_factor = 1 - (np.abs(slopes - 25) / 50)\n",
        "\n",
        "# Calculate annual solar savings (kWh/year)\n",
        "# Base: ~150 kWh per sq meter per year * efficiency factors\n",
        "solar_savings = (\n",
        "    roof_areas * 150 * solar_irradiance_factor *\n",
        "    orientation_multiplier * slope_factor *\n",
        "    np.random.uniform(0.85, 1.15, n_samples)  # Add some realistic variance\n",
        ")\n",
        "\n",
        "# Electricity Consumption (kWh/month)\n",
        "# Rough estimate based on roof area as proxy for house size\n",
        "# Larger homes typically consume more electricity\n",
        "# Average Indian household: 200-400 kWh/month\n",
        "electricity_consumption = (\n",
        "    100 +  # Base consumption\n",
        "    (roof_areas / 2) +  # House size factor\n",
        "    np.random.uniform(-50, 50, n_samples)  # Random variance\n",
        ")\n",
        "\n",
        "# Add targets to dataframe\n",
        "data_5features['solar_savings'] = solar_savings\n",
        "data_5features['electricity_consumption'] = electricity_consumption\n",
        "\n",
        "print(f\"Solar savings range: {solar_savings.min():.2f} to {solar_savings.max():.2f} kWh/year\")\n",
        "print(f\"Electricity consumption range: {electricity_consumption.min():.2f} to {electricity_consumption.max():.2f} kWh/month\")\n",
        "print(\"\\nDataset with targets:\")\n",
        "print(data_5features.head())"
      ],
      "metadata": {
        "id": "WeSiA4b7i7n9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Train Solar Prediction Model (5 features)\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Training Solar Prediction Model\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Define features and target\n",
        "FEATURES = ['latitude', 'longitude', 'roof_area', 'orientation_code', 'slope']\n",
        "X = data_5features[FEATURES].values\n",
        "y_solar = data_5features['solar_savings'].values\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train_solar, y_test_solar = train_test_split(\n",
        "    X, y_solar, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"\\nTraining samples: {X_train.shape[0]}\")\n",
        "print(f\"Test samples: {X_test.shape[0]}\")\n",
        "print(f\"Features: {FEATURES}\")\n",
        "\n",
        "# Train GradientBoostingRegressor\n",
        "print(\"\\nTraining GradientBoostingRegressor...\")\n",
        "solar_model = GradientBoostingRegressor(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=5,\n",
        "    random_state=42\n",
        ")\n",
        "solar_model.fit(X_train, y_train_solar)\n",
        "\n",
        "# Evaluate\n",
        "y_pred_solar = solar_model.predict(X_test)\n",
        "mae_solar = mean_absolute_error(y_test_solar, y_pred_solar)\n",
        "mse_solar = mean_squared_error(y_test_solar, y_pred_solar)\n",
        "rmse_solar = np.sqrt(mse_solar)\n",
        "r2_solar = r2_score(y_test_solar, y_pred_solar)\n",
        "\n",
        "print(\"\\n--- Solar Model Performance ---\")\n",
        "print(f\"MAE: {mae_solar:.2f} kWh/year\")\n",
        "print(f\"RMSE: {rmse_solar:.2f} kWh/year\")\n",
        "print(f\"R² Score: {r2_solar:.4f}\")\n",
        "\n",
        "# Save the model\n",
        "model_filename = 'solar_model_5features.joblib'\n",
        "joblib.dump(solar_model, model_filename)\n",
        "print(f\"\\nModel saved as: {model_filename}\")"
      ],
      "metadata": {
        "id": "CJDpT1WJjNLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Train Electricity Consumption Model (5 features)\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Training Electricity Consumption Model\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Use same features\n",
        "y_electricity = data_5features['electricity_consumption'].values\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train_elec, y_test_elec = train_test_split(\n",
        "    X, y_electricity, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"\\nTraining samples: {X_train.shape[0]}\")\n",
        "print(f\"Test samples: {X_test.shape[0]}\")\n",
        "print(f\"Features: {FEATURES}\")\n",
        "\n",
        "# Train XGBRegressor\n",
        "print(\"\\nTraining XGBRegressor...\")\n",
        "electricity_model = XGBRegressor(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=5,\n",
        "    random_state=42\n",
        ")\n",
        "electricity_model.fit(X_train, y_train_elec)\n",
        "\n",
        "# Evaluate\n",
        "y_pred_elec = electricity_model.predict(X_test)\n",
        "mae_elec = mean_absolute_error(y_test_elec, y_pred_elec)\n",
        "mse_elec = mean_squared_error(y_test_elec, y_pred_elec)\n",
        "rmse_elec = np.sqrt(mse_elec)\n",
        "r2_elec = r2_score(y_test_elec, y_pred_elec)\n",
        "\n",
        "print(\"\\n--- Electricity Model Performance ---\")\n",
        "print(f\"MAE: {mae_elec:.2f} kWh/month\")\n",
        "print(f\"RMSE: {rmse_elec:.2f} kWh/month\")\n",
        "print(f\"R² Score: {r2_elec:.4f}\")\n",
        "\n",
        "# Save the model\n",
        "model_filename = 'electricity_model_5features.joblib'\n",
        "joblib.dump(electricity_model, model_filename)\n",
        "print(f\"\\nModel saved as: {model_filename}\")"
      ],
      "metadata": {
        "id": "REFQsCPdjUr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Test the models with sample data\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Testing Models with Sample Input\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Sample input matching your frontend (Bangalore coordinates)\n",
        "sample_input = np.array([\n",
        "    [12.9716, 77.5946, 120, 2, 25]  # lat, lon, roof_area, orientation(South), slope\n",
        "])\n",
        "\n",
        "print(\"\\nSample Input:\")\n",
        "print(f\"Latitude: {sample_input[0][0]}\")\n",
        "print(f\"Longitude: {sample_input[0][1]}\")\n",
        "print(f\"Roof Area: {sample_input[0][2]} sq.m\")\n",
        "print(f\"Orientation: {sample_input[0][3]} (2=South)\")\n",
        "print(f\"Slope: {sample_input[0][4]} degrees\")\n",
        "\n",
        "# Make predictions\n",
        "solar_prediction = solar_model.predict(sample_input)[0]\n",
        "electricity_prediction = electricity_model.predict(sample_input)[0]\n",
        "\n",
        "print(\"\\n--- Predictions ---\")\n",
        "print(f\"Solar Savings: {solar_prediction:.2f} kWh/year\")\n",
        "print(f\"Electricity Consumption: {electricity_prediction:.2f} kWh/month\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"SUCCESS! Models are ready for deployment\")\n",
        "print(\"=\"*50)"
      ],
      "metadata": {
        "id": "vDQrLXVvjprf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Download Models to Local Machine\n",
        "# ============================================\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "print(\"\\nDownloading trained models...\")\n",
        "print(\"These files will be saved to your Downloads folder.\\n\")\n",
        "\n",
        "# Download solar model\n",
        "print(\"Downloading solar_model_5features.joblib...\")\n",
        "files.download('solar_model_5features.joblib')\n",
        "\n",
        "# Download electricity model\n",
        "print(\"Downloading electricity_model_5features.joblib...\")\n",
        "files.download('electricity_model_5features.joblib')\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"DOWNLOAD COMPLETE!\")\n",
        "print(\"=\"*50)\n",
        "print(\"\\nNext steps:\")\n",
        "print(\"1. Replace the old model files in your Flask backend directory\")\n",
        "print(\"2. Update your app.py to load these new 5-feature models:\")\n",
        "print(\"   - solar_model = joblib.load('solar_model_5features.joblib')\")\n",
        "print(\"   - electricity_model = joblib.load('electricity_model_5features.joblib')\")\n",
        "print(\"3. The models now expect exactly 5 features in this order:\")\n",
        "print(\"   [latitude, longitude, roof_area, orientation_code, slope]\")\n",
        "print(\"4. Restart your Flask server and test!\")"
      ],
      "metadata": {
        "id": "7l_dwECWj6mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sokZMOcwkMTS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}